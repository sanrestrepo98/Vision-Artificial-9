{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 5 Morfología y Extracción de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan una serie de ejercicios de carácter calificable.\n",
    "\n",
    "<br> Deben realizarse en los grupos de trabajo asignados y subirse al GitHub respectivo </br>\n",
    "\n",
    "No es necesario concluir, pero deben presentarse las respuestas de forma <b> ordenada </b>\n",
    "\n",
    "## Fecha límite de entrega: Jueves 8 de agosto a media noche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "\n",
    "Lea la imagen \"res/jirafa.png\" y realice:\n",
    "\n",
    "1. Extracción de bordes mediante erosión y dilatación.\n",
    "2. Extracción de bordes mediante la función gradiente.\n",
    "3. Extracción de bordes mediante la operación XOR entre dilatación y erosión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución\n",
    "\n",
    "#### 1.1. Extracción de bordes mediante erosión y dilatación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.morphology as morph\n",
    "import cv2\n",
    "\n",
    "#Crear un kernel \n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "#Leer imagen de entrada y binarizarla\n",
    "img = skimage.io.imread('res/jirafa.png', as_gray=True)\n",
    "\n",
    "#Realizar extracción de bordes bajo dilatación y erosión\n",
    "dilatacion = morph.binary_dilation(img,kernel)\n",
    "erosion = morph.binary_erosion(img,kernel)\n",
    "\n",
    "#Crear subplot 1x3 que muestre imagen original y bordes\n",
    "fig, ax = plt.subplots(1,3, figsize=(20, 10))\n",
    "ax[0].set_title('imagen original')\n",
    "ax[0].imshow(img, cmap='gray')\n",
    "ax[1].set_title('bordes con erosion')\n",
    "ax[1].imshow(np.logical_xor(img,erosion), cmap='gray')\n",
    "ax[2].set_title('bordes con dilatacion')\n",
    "ax[2].imshow(np.logical_xor(img, dilatacion), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Extracción de bordes mediante la función gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicar la operación gradiente de OpenCv con el kernel\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "#Crear figura que muestre las imagenes\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
    "ax[0].set_title('imagen original')\n",
    "ax[0].imshow(img, cmap='gray')\n",
    "ax[1].set_title('gradiente')\n",
    "ax[1].imshow(gradient, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Extracción de bordes mediante la operación XOR entre dilatación y erosión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar la imagen gradient por la expresión XOR\n",
    "gradient = np.logical_xor(erosion,dilatacion)\n",
    "\n",
    "plt.imshow(gradient, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "\n",
    "<br> Lea la imagen \"res/silueta.png\" y obsérvela cuidadosamente. </br>\n",
    "<br> Lea también, la imagen \"res/silueta2.png\" y repita el proceso. </br>\n",
    "<br> Las imágenes tienen dos tipos de ruido distintos colocados con una serie de cuidadosas operaciones hechas en paint </br>\n",
    "\n",
    "Utilice morfologías de  apertura y cierre (escogiendo la máscara adecuada) para eliminar el ruido sin afectar demasiado la silueta de la jirafa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solución\n",
    "\n",
    "2.1 Eliminar ruido de la imágen \"silueta\" con APERTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.morphology as morph\n",
    "\n",
    "#Definir radio y crear una máscara\n",
    "radius = 1\n",
    "\n",
    "selem = morph.disk(radius)\n",
    "\n",
    "#Leer imagen de entrada y realizar una apertura con la máscara creada bajo la función\n",
    "#de skimage, cuyos parámetros requieren imagen de entrada y una máscara\n",
    "img = skimage.io.imread('res/silueta.png', as_grey=True)\n",
    "apertura = morph.binary_opening(img,selem)\n",
    "\n",
    "#Crear subplot 1x2 que muestre imagen original y apertura \n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8, 4))\n",
    "ax1.set_title('imagen original')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('apertura - shape: disk(radius='+str(radius)+')')\n",
    "ax2.imshow(apertura, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Eliminar ruido de la imágen \"silueta2\" con CIERRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.morphology as morph\n",
    "\n",
    "#Crear máscara\n",
    "radius = 1\n",
    "selem = morph.disk(radius)\n",
    "\n",
    "#Leer imagen de entrada y aplicar la operación cierre de skimage, cuyos parámetros\n",
    "#requieren imagen de entrada y una máscara\n",
    "img = skimage.io.imread('res/silueta2.png', as_grey=True)\n",
    "cierre = morph.binary_closing(img,selem)\n",
    "\n",
    "#Crear subplot 1x2 que muestre imagen original e imagen bajo cierre\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8, 4))\n",
    "ax1.set_title('imagen original')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('cierre - shape: disk(radius='+str(radius)+')')\n",
    "ax2.imshow(cierre, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "\n",
    "1. Lea la imagen \"res/jirafa.png\" en escala de grises.\n",
    "\n",
    "Realice un etiquetado de regiones escogiendo la máscara correcta (no necesariamente un rectángulo, prueba un disco o la identidad).\n",
    "\n",
    "<img src = \"res/etiq.png\">\n",
    "\n",
    "<center><i>Figura: Solución aproximada</i></center>\n",
    "\n",
    "Imprima el número de etiquetas (Debe ser 1)\n",
    "\n",
    "2. Ya que ha leido la imagen \"res/jirafa.png\" utilice el método de esqueletización de Zhang para obtener el esqueleto de ésta imagen (recuerde que es una imagen binaria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No olvide revisar el Pipeline de segmentación que se encuentra en el notebook de la clase 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1 Leer la imagen en escala de grises\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.morphology as morph\n",
    "import skimage.color as color\n",
    "\n",
    "#Máscara y lectura de imagen\n",
    "\n",
    "mask = morph.ball(12)\n",
    "jir = skimage.io.imread('res/jirafa.png', as_gray=True)\n",
    "jirB = jir >=  0.5\n",
    "\n",
    "#Etiquetado \n",
    "labels, num_labels = morph.label (jirB, neighbors=4, return_num=True, connectivity = 1)\n",
    "jir_label = color.label2rgb (labels, image = jir)\n",
    "\n",
    "#Etiquetas\n",
    "print (num_labels)\n",
    "\n",
    "## 3.2 Esqueletización\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "skeleton = skeletonize(jirB)\n",
    "plt.imshow (skeleton)\n",
    "### El esqueleto se ve muy gracioso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\n",
    "\n",
    "Cree una imagen de ceros (np.zeros()) de 600x600, posteriormente un cuadrado de 100x100, cuyo <i>start</i> está en la coordenada [200,200] (Utilice la función rectangle de skimage, es un proceso análogo a dibujar la elipse)\n",
    "\n",
    "\n",
    "<img src = \"res/pis.png\">\n",
    "\n",
    "<center><i>Figura: Cuadrado</i></center>\n",
    "\n",
    "Una vez tenga la imagen anterior, realice los siguientes pasos (Debe realizar UN SOLO PLOT POR CADA NUMERAL listado a continuación)\n",
    "\n",
    "1. Plotee el cuadrado que creó, imprima el área y el perímetro respectivos.\n",
    "2. Imprima el cuadrado con el centroide, adicionalmente imprima las coordenadas del centroide.\n",
    "3. Imprima el cuadrado rodeado por el rectángulo más pequeño que lo rodea (si quiere puede mostrarlo con el centroide)\n",
    "4. Muestre las distancias respecto al contorno.\n",
    "5. Imprima el cuadrado con el centroide y el contorno, junto a la medida entre el contorno y el centroide.\n",
    "6. ¿Cuál es el diámetro equivalente? imprímalo.\n",
    "7. Imprima los momentos de HU y sus logaritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "img = np.zeros((600,600))\n",
    "img[100:200,100:200] = np.ones((100,100))\n",
    "\n",
    "label_img = label(img)\n",
    "\n",
    "#Generar un vector de propiedades de la región\n",
    "props = regionprops(label_img)\n",
    "\n",
    "#Imprimir el perímetro de la lista en la posición 0 de la matriz props\n",
    "print(\"El perímetro es: \", props[0].perimeter, \" píxeles.\")\n",
    "\n",
    "#Calcular el área de la matriz en la posición 0, por tanto del caballo\n",
    "print(\"El área es: \", props[0].area, \" píxeles.\")\n",
    "\n",
    "plt.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener las coordenadas x,y del centroide de la región etiquetada\n",
    "y0, x0 = props[0].centroid\n",
    "print(\"El centroide es: \", props[0].centroid)\n",
    "\n",
    "#Utilizar la función bbox para buscar los 4 puntos que conforman el rectángulo más pequeño\n",
    "#que puede contener la región etiquetada\n",
    "minr, minc, maxr, maxc = props[0].bbox\n",
    "bx = (minc, maxc, maxc, minc, minc)\n",
    "by = (minr, minr, maxr, maxr, minr)\n",
    "\n",
    "#Imprimir la imagen con el centroide pintado de verde\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 6))\n",
    "ax.set_title('Imagen')\n",
    "ax.plot(x0, y0, '.g', markersize=15)\n",
    "ax.plot(x0, y0, '.g', markersize=15)\n",
    "ax.plot(bx, by, '-b', linewidth=2.5)\n",
    "ax.imshow(label_img, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "#Definir función de la distancia euclidiana para posiciones de matrices\n",
    "\n",
    "def euc_distance(p1, p2):\n",
    "    distance = math.sqrt( (p1[0]-p2[0])**2 + (p1[1]-p2[1])**2 )\n",
    "    return distance\n",
    "\n",
    "#Encontrar el centroide, la posición y,x, y dibujar los contornos\n",
    "centroid = props[0].centroid\n",
    "(y0, x0) = centroid\n",
    "contours = find_contours(label_img, 0)\n",
    "\n",
    "contour = contours[0]\n",
    "\n",
    "#Definir los parámetros de entrada\n",
    "dist_min = None\n",
    "min_point = None\n",
    "dist_max = None\n",
    "max_point = None\n",
    "\n",
    "#Ciclo for para iterar las posiciones x,y en la matriz de contornos\n",
    "for point in contour:\n",
    "    \n",
    "    #Definir los puntos xi, yi del contorno, calcular su distancia euclídea\n",
    "    #respecto al centroide\n",
    "    xi = point[1]\n",
    "    yi = point[0]\n",
    "    dist = euc_distance( (x0,y0) , (xi,yi)  )\n",
    "    #Condicionales para buscar el punto más cercano y el más lejano al centroide\n",
    "    if not dist_min or dist < dist_min:\n",
    "        dist_min = dist\n",
    "        min_point = (xi, yi)\n",
    "    if not dist_max or dist > dist_max:\n",
    "        dist_max = dist\n",
    "        max_point = (xi, yi)\n",
    "\n",
    "#Mostrar en la figura la imagen original, contorno dibujado, centroide y puntos más cercanos\n",
    "#y alejados del mismo\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 6))\n",
    "ax.plot(x0, y0, '.g', markersize=15)\n",
    "ax.plot(max_point[0], max_point[1], '.r', markersize=15)\n",
    "ax.plot(min_point[0], min_point[1], '.b', markersize=15)\n",
    "for n, contour in enumerate(contours):\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "ax.plot((x0, max_point[0]), (y0, max_point[1]), '-r', linewidth=2.5)\n",
    "ax.plot((x0, min_point[0]), (y0, min_point[1]), '-r', linewidth=2.5)\n",
    "#ax.plot(bx, by, '-b', linewidth=2.5)\n",
    "ax.set_title('Imagen')\n",
    "ax.imshow(label_img, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "print(\"Centroide: (\"+str(x0)+\",\"+str(y0)+\").\" )\n",
    "print(\"Medida el contorno (max):\", ((x0 - max_point[0])**2 + (y0 - max_point[1])**2)**(1/2))\n",
    "print(\"Medida el contorno (min):\", ((x0 - min_point[0])**2 + (y0 - min_point[1])**2)**(1/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Utilizar la función equivalent_diameter para calcular el diámetro equivalente a la \n",
    "#región etiquetada\n",
    "diam_equiv = props[0].equivalent_diameter\n",
    "\n",
    "#Calcular la orientación y el centroide de la región\n",
    "orientation = props[0].orientation\n",
    "centroid = props[0].centroid\n",
    "(y0,x0) = centroid\n",
    "\n",
    "minr, minc, maxr, maxc = props[0].bbox\n",
    "\n",
    "#Calcular los extremos de las líneas rectas cuyo origen es el centroide\n",
    "x1 = x0 + math.cos(orientation) * 0.5 * diam_equiv\n",
    "y1 = y0 - math.sin(orientation) * 0.5 * diam_equiv\n",
    "x2 = x0 - math.sin(orientation) * 0.5 * diam_equiv\n",
    "y2 = y0 - math.cos(orientation) * 0.5 * diam_equiv\n",
    "\n",
    "#Imprimir el diámetro equivalente\n",
    "print(\"El diametro equivalente es de \", diam_equiv, \" píxeles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = regionprops(label_img)\n",
    "momentos_hu = props[0].moments_hu\n",
    "\n",
    "#Imprimir la matriz de momentos hu\n",
    "print(\"Momentos Hu: \", momentos_hu)\n",
    "\n",
    "#Aplicar logaritmo a la matriz de momentos hu e imprimirla\n",
    "momentos_hu_log = - np.sign(momentos_hu) * np.log(np.abs(momentos_hu) + 1e-15)\n",
    "\n",
    "print(\"Logaritmos de los Momentos Hu: \", momentos_hu_log)\n",
    "\n",
    "#Mostrar la imagen sobre la cual se trabaja\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 6))\n",
    "\n",
    "\n",
    "ax.set_title('Imagen')\n",
    "ax.imshow(label_img, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\n",
    "\n",
    "Lea la imagen \"res/cancer.bmp\" y la máscara \"res/lesion.bmp\", utilice los algoritmos de extracción de características para encontrar los estadísticos de primer y segundo orden de esta imagen. Preste especial atención a este proceso individual, puesto que en el ejercicio guiado lo hará para varias imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Guiado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es, mediante 5 imágenes de un dataset de melanomas, mostrar al estudiante cuál es el proceso de extracción de características.\n",
    "\n",
    "No duden en ir a la carpeta PH2Dataset para observar la información allí consignada, de igual forma las subcarpetas que contienen la imagen a estudiar y sus máscaras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer estas utilidades, librerías a utilizar y funciones de lectura que necesitaremos para facilitar el trabajo posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from os.path import join, splitext, basename, abspath\n",
    "from os import listdir\n",
    "from skimage.io import imread\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import math\n",
    "from skimage import morphology\n",
    "from skimage.measure import label, regionprops\n",
    "import cv2\n",
    "from skimage import measure\n",
    "from scipy.ndimage import rotate\n",
    "import math \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class MissingAttributeException(Exception):\n",
    "    def __init__(self, attribute):\n",
    "        super(MissingAttributeException, self).__init__(\n",
    "            'The <{}> attribute is not contained in the dataset'.format(attribute)\n",
    "        )\n",
    "\n",
    "\n",
    "class BaseDataset:\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self, dataset_path):\n",
    "        self.__dataset_path = abspath(dataset_path)\n",
    "        self.__image_list = self.load_dataset(self.__dataset_path)\n",
    "        self.__sample = self.__image_list\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_dataset(self, dataset_path):\n",
    "        '''\n",
    "        It must return a vector of dictionary in the followed way (keys with * are mandatory):\n",
    "        image_data = [\n",
    "                        {\n",
    "                            'image_filename': <* image filename>,\n",
    "                            'imageName': <* image name>,\n",
    "                            'ground_truth_filename': <ground_truth_filename>,\n",
    "                            'class': <class number the image belong to>,\n",
    "                            'labels': <vector of string labels associates with the image>\n",
    "                        },\n",
    "                        {...}\n",
    "                    ]\n",
    "        :param dataset_path: base path for the dataset\n",
    "        :return: a list of dictionaries containing the dataset information. One entry per image in the dataset\n",
    "        '''\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def read_data(self, filename):\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def has_class(self):\n",
    "        return False\n",
    "\n",
    "    @abstractmethod\n",
    "    def has_labels(self):\n",
    "        return False\n",
    "\n",
    "    @abstractmethod\n",
    "    def has_ground_truth(self):\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def image_names(self):\n",
    "        return [i['imageName'] for i in self.__sample]\n",
    "\n",
    "    @property\n",
    "    def num_images(self):\n",
    "        return len(self.__sample)\n",
    "\n",
    "    def reset_sample(self):\n",
    "        self.__sample = self.__image_list\n",
    "\n",
    "    def set_sample(self, **kwargs):\n",
    "        if 'percentage' in kwargs:\n",
    "            p = kwargs['percentage']\n",
    "            N = len(self.__image_list)\n",
    "            rn = np.random.rand(N)\n",
    "            j = np.argsort(rn)[0:int(np.floor(p * N))]\n",
    "            self.__sample = [self.__image_list[i] for i in j]\n",
    "        elif 'image_names' in kwargs:\n",
    "            i_names = kwargs['image_names']\n",
    "            self.__sample = [data for data in self.__image_list if data['imageName'] in i_names]\n",
    "        elif 'image_indices' in kwargs:\n",
    "            image_idxs = kwargs['image_indices']\n",
    "            self.__sample = [self.__image_list[i] for i in image_idxs]\n",
    "        else:\n",
    "            print('No samples was selected. All images will be used.')\n",
    "            self.reset_sample()\n",
    "\n",
    "    def exclude_from_sample(self, **kwargs):\n",
    "        if 'image_names' in kwargs:\n",
    "            i_names = kwargs['image_names']\n",
    "            self.__sample = [data for data in self.__sample if data['imageName'] not in i_names]\n",
    "        elif 'image_indices' in kwargs:\n",
    "            image_idxs = kwargs['image_indices']\n",
    "            self.__sample = [self.__sample[i] for i in range(len(self.__sample)) if i not in image_idxs]\n",
    "        else:\n",
    "            print('No elements were excluded from the sample.')\n",
    "\n",
    "    def get_image_data(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if 'loaded' not in current_image or not current_image['loaded']:\n",
    "            current_image['data'] = self.read_data(current_image['image_filename'])\n",
    "            current_image['loaded'] = True\n",
    "\n",
    "        return current_image['data']\n",
    "\n",
    "    def get_ground_truth_data(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if self.has_ground_truth():\n",
    "            if 'ground_truth_loaded' not in current_image or not current_image['ground_truth_loaded']:\n",
    "                current_image['ground_truth_data'] = self.read_data(current_image['ground_truth_filename'])\n",
    "                current_image['ground_truth_loaded'] = True\n",
    "\n",
    "            return current_image['ground_truth_data']\n",
    "        else:\n",
    "            raise MissingAttributeException('ground_truth_data')\n",
    "\n",
    "    def get_image_class(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if self.has_class():\n",
    "            return current_image['class']\n",
    "        else:\n",
    "            raise MissingAttributeException('class')\n",
    "\n",
    "    def get_image_labels(self, idx_image):\n",
    "        current_image = self.__sample[idx_image]\n",
    "\n",
    "        if self.has_labels():\n",
    "            return current_image['labels']\n",
    "        else:\n",
    "            raise MissingAttributeException('labels')\n",
    "\n",
    "\n",
    "class MPEG7Dataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Concrete implementation of the MPEG-7 Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, basepath):\n",
    "        self.image_list = [{\n",
    "                               'image_filename': fn,\n",
    "                               'imageName': splitext(basename(fn))[0],\n",
    "                               'ground_truth_filename': None,\n",
    "                               'class': None,  # TODO,\n",
    "                               'labels': None\n",
    "                           } for fn in glob(join(basepath, 'MPEG7/original/*.gif'))]\n",
    "\n",
    "class PH2Dataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Concrete implementation of the MPEG-7 Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_path):\n",
    "        BaseDataset.__init__(self, base_path)\n",
    "\n",
    "    def load_dataset(self, dataset_path):\n",
    "        image_list = []\n",
    "        images_base_folder = join(dataset_path, 'PH2 Dataset images')\n",
    "        image_dirs = [f for f in listdir(images_base_folder) if not f.startswith('.')]\n",
    "\n",
    "        #Reads the info in the XLSX file\n",
    "        df = pd.read_excel(join(dataset_path, 'PH2_dataset.xlsx'))\n",
    "        classes = []\n",
    "        for i in range(len(image_dirs)):\n",
    "\n",
    "            cell_common_nevus = df.iloc[i + 11, 2]\n",
    "            cell_atypical_nevus = df.iloc[i + 11, 3]\n",
    "            cell_melanoma = df.iloc[i + 11, 4]\n",
    "\n",
    "            if cell_common_nevus == 'X':\n",
    "                image_class = 1\n",
    "            elif cell_atypical_nevus == 'X':\n",
    "                image_class = 2\n",
    "            else:\n",
    "                image_class = 3\n",
    "\n",
    "            classes.append({\n",
    "                'name': df.iloc[i + 11, 0],\n",
    "                'class': image_class\n",
    "            })\n",
    "\n",
    "        for image_folder_name in image_dirs:\n",
    "            filename = join(images_base_folder, image_folder_name, image_folder_name + '_Dermoscopic_Image',\n",
    "                            image_folder_name + '.bmp')\n",
    "            ground_truth_filename = join(images_base_folder, image_folder_name, image_folder_name + '_lesion',\n",
    "                                         image_folder_name + '_lesion.bmp')\n",
    "\n",
    "\n",
    "\n",
    "            #image class\n",
    "            results = list(filter(lambda all_classes: all_classes['name'] == image_folder_name, classes))\n",
    "            if len(results) > 0:\n",
    "                c = results[0]['class']\n",
    "            else:\n",
    "                c = 1\n",
    "\n",
    "            image_list.append({\n",
    "                'image_filename': filename,\n",
    "                'imageName': image_folder_name,\n",
    "                'ground_truth_filename': ground_truth_filename,\n",
    "                'class': c,\n",
    "                'labels': ['', ''] #TODO: llenar esto\n",
    "            })\n",
    "\n",
    "        return image_list\n",
    "\n",
    "    def read_data(self, filename):\n",
    "        return imread(filename)\n",
    "\n",
    "    def has_class(self):\n",
    "        return True\n",
    "\n",
    "    def has_labels(self):\n",
    "        return True\n",
    "\n",
    "    def has_ground_truth(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv(im):\n",
    "    return cv2.cvtColor(im, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def rgb_to_lab(im):\n",
    "    return cv2.cvtColor(im, cv2.COLOR_RGB2LAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura del dataset\n",
    "\n",
    "Por cuestiones de portabilidad y velocidad de procesamiento, este ejercicio posee 5 imágenes asociadas al dataset. Vamos a leer el excel PH2Dataset y las imágenes. Si tienes algún problema con este paso, asegúrate de tener tu carpeta organizada de la siguiente manera:\n",
    "\n",
    "<img src = \"res/ejemplo.png\">\n",
    "\n",
    "Y dentro de la carpeta PH2Dataset:\n",
    "\n",
    "<img src = \"res/example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PH2Dataset(\"PH2Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = dataset.load_dataset(\"PH2Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de las imágenes\n",
    "\n",
    "Recuerda que nuestro Dataset consta de información consignada en un archivo y de imágenes con su respectivo label que corresponde al ground truth. Corre este código para leer las imágenes dentro del Dataset. \n",
    "\n",
    "Tenemos 5 imágenes, por tanto si intentas hacer que idd>4, arrojará error. (¡pruebalo!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = 0\n",
    "image1 = dataset.read_data(images[idd][\"image_filename\"])\n",
    "image1_mask = dataset.read_data(images[idd][\"ground_truth_filename\"])\n",
    "mask_3c = np.zeros((image1.shape), np.uint8)\n",
    "mask_3c[:,:,0] = image1_mask\n",
    "mask_3c[:,:,1] = image1_mask\n",
    "mask_3c[:,:,2] = image1_mask\n",
    "image1 = image1 * (mask_3c > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase asociada a la imagen\n",
    "\n",
    "Cada imagen tiene una clase asociada que en algún paso de clasificación se intentará predecir, por ahora, varía \"idd\" y verifica la clase de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[idd][\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para extracción de características\n",
    "\n",
    "Es hora de extraer las características de las imágenes, como bien observaste con el ejercicio individual del melanoma, al multiplicarlo por la máscara asociada y aplicar algoritmos de extracción de estadísticos de primer y segundo orden pueden obtenerse una cantidad enorme de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lab_hsv_features(im, mask, features):\n",
    "    #La imagen de entrada debe estar en el espacio RGB\n",
    "    #Extraer el tamaño de la imagen de entrada y convertirla a LAB y HSV\n",
    "    shape = np.shape(im)\n",
    "    im_lab = rgb_to_lab(im)\n",
    "    im_hsv = rgb_to_hsv(im)\n",
    "    \n",
    "    #Definir los canales  por separado\n",
    "    s = im_hsv[:,:,1]\n",
    "    v = im_hsv[:,:,2]\n",
    "    \n",
    "    a = im_lab[:,:,1]\n",
    "    b = im_lab[:,:,2]\n",
    "    #Definir listas vacías de canales h,s,v\n",
    "    a_1 = []\n",
    "    b_1 = []\n",
    "    s_1 = []\n",
    "    v_1= []\n",
    "    \n",
    "    #Recorrer cada posición i,j de la matriz de la imagen de entrada\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            #Condicional, si la máscara en la posición i,j es un array verdadero añadir\n",
    "            #a cada canal del nuevo HSV el píxel en esta posición\n",
    "            if((mask[i][j] == np.array([True, True, True])).all() ):\n",
    "                s_1.append(s[i][j])\n",
    "                v_1.append(v[i][j])\n",
    "                a_1.append(a[i][j])\n",
    "                b_1.append(a[i][j])\n",
    "                \n",
    "    #Utilizar features para guardar los valores de media, desviación estándar, kurtosis y sesgo\n",
    "    #de cada uno de los canales h_1, s_1, v_1\n",
    "    features['s_mean'] = np.mean(s_1)\n",
    "    features['s_std'] = np.std(s_1)\n",
    "    features['s_kurtosis'] = kurtosis(s_1)\n",
    "    features['s_skew'] = skew(s_1)\n",
    "    features['v_kurtosis'] = kurtosis(v_1)\n",
    "    features['v_skew'] = skew(v_1)\n",
    "    features['v_mean'] = np.mean(v_1)\n",
    "    features['v_std'] = np.std(v_1)\n",
    "    features['lab_a_mean'] = np.mean(a_1)\n",
    "    features['lab_a_std'] = np.std(a_1)\n",
    "    features['lab_a_kurtosis'] = kurtosis(a_1)\n",
    "    features['lab_a_skew'] = skew(a_1)\n",
    "    features['lab_b_kurtosis'] = kurtosis(b_1)\n",
    "    features['lab_b_skew'] = skew(b_1)\n",
    "    features['lab_b_mean'] = np.mean(b_1)\n",
    "    features['lab_b_std'] = np.std(b_1)\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_moments_hu(props, features):\n",
    "    moments_hu = props.moments_hu\n",
    "    moments_hu = np.sign(moments_hu) * np.log(np.abs(moments_hu))\n",
    "    features['hu0'] = moments_hu[0]\n",
    "    features['hu1'] = moments_hu[1]\n",
    "    features['hu2'] = moments_hu[2]\n",
    "    features['hu3'] = moments_hu[3]\n",
    "    features['hu4'] = moments_hu[4]\n",
    "    features['hu5'] = moments_hu[5]\n",
    "    features['hu6'] = moments_hu[6]\n",
    "    return features\n",
    "\n",
    "def get_features_perimeter(mask, features):\n",
    "    contours = measure.find_contours(mask, 0.8)\n",
    "    features['perimeter'] = contours[0].shape[0]\n",
    "    return features\n",
    "\n",
    "def get_features_area(props, features):\n",
    "    features['area'] = props.area\n",
    "    features['convex_area'] = props.convex_area\n",
    "    features['area_to_convex_ratio'] = props.area/props.convex_area\n",
    "    features['compacity'] = props.perimeter**2/props.area\n",
    "    features['roundness'] = 4*math.pi*props.area /(props.perimeter**2)\n",
    "    features['area_perimeter_ratio'] = props.area / props.perimeter\n",
    "    features['elongation'] = props.major_axis_length/props.minor_axis_length\n",
    "    features['major_axis_length'] = props.major_axis_length\n",
    "    features['minor_axis_length'] = props.minor_axis_length\n",
    "    features['solidity1'] = props.area/props.convex_area\n",
    "    features['solidity2'] = props.area / props.filled_area\n",
    "    return features\n",
    "\n",
    "#Definir función para extraer características del espacio RGB\n",
    "def get_rgb_features(im,mask, features):\n",
    "    #Crear una matriz del mismo tamaño de la imagen de entrada, leer los canales R,G,B y \n",
    "    #crear listas vacías donde se aplica la máscara\n",
    "    shape = np.shape(im)\n",
    "    r = im[:,:,0]\n",
    "    g = im[:,:,1]\n",
    "    b = im[:,:,2]\n",
    "    r_1 = []\n",
    "    g_1 = []\n",
    "    b_1 = []\n",
    "    #Recorrer las posiciones i,j de la matriz de la imagen de entrada\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            #Condicional, si la máscara en la posición i,j es un array de True, añadir\n",
    "            #a cada canal del nuevo espacio RGB el píxel en esta posición\n",
    "            if( (mask[i][j] == np.array([True, True, True])).all() ): \n",
    "                r_1.append(r[i][j])\n",
    "                g_1.append(g[i][j])\n",
    "                b_1.append(b[i][j])\n",
    "    #Utilizar features para guardar los valores de media, desv.estandar, kurtosis y sesgo\n",
    "    #de los canales r_1,g_1,b_1\n",
    "    features['r_mean'] = np.mean(r_1)\n",
    "    features['r_std'] = np.std(r_1)\n",
    "    features['r_kurtosis'] = kurtosis(r_1)\n",
    "    features['r_skew'] = skew(r_1)\n",
    "    features['g_mean'] = np.mean(g_1)\n",
    "    features['g_std'] = np.std(g_1)\n",
    "    features['b_kurtosis'] = kurtosis(b_1)\n",
    "    features['b_skew'] = skew(b_1)\n",
    "    features['b_mean'] = np.mean(b_1)\n",
    "    features['b_std'] = np.std(b_1)\n",
    "    features['g_kurtosis'] = kurtosis(g_1)\n",
    "    features['g_skew'] = skew(g_1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_pipeline(img, mask):\n",
    "    #Crear el diccionario para guardar las características\n",
    "    features = {}\n",
    "    label_img = label(mask)\n",
    "    props = regionprops(label_img)[0]\n",
    "    mask_3c = np.zeros((img.shape), np.uint8)\n",
    "    mask_3c[:,:,0] = mask\n",
    "    mask_3c[:,:,1] = mask\n",
    "    mask_3c[:,:,2] = mask\n",
    "    features = get_moments_hu(props, features)\n",
    "    features = get_features_area(props, features)\n",
    "    features = get_rgb_features(img,mask_3c,features)\n",
    "    features = get_lab_hsv_features(img,mask_3c,features)\n",
    "    features = get_features_perimeter(mask, features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraigamos las características de una sola imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_base = features_pipeline(image1, image1_mask > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realicemos un for loop para extraer las características de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(features_base.keys())\n",
    "columns.append('class')\n",
    "df = pd.DataFrame(columns=columns)\n",
    "#Ir desde i hasta el # de datos del dataset PH2Dataset\n",
    "for i in range(5):\n",
    "    image = dataset.read_data(images[i][\"image_filename\"])\n",
    "    mask = dataset.read_data(images[i][\"ground_truth_filename\"])\n",
    "    mask_3c = np.zeros((image.shape), np.uint8)\n",
    "    mask_3c[:,:,0] = mask\n",
    "    mask_3c[:,:,1] = mask\n",
    "    mask_3c[:,:,2] = mask\n",
    "    image = image * (mask_3c > 0)\n",
    "    features = features_pipeline(image, mask > 0)\n",
    "    df.loc[i] = [features[feature] for feature in features_base.keys()]+[images[i][\"class\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué obtuvimos entonces?\n",
    "\n",
    "En este momento, si te fijas construimos un dataframe de pandas, llamado \"df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"df\" contiene la información de las 46 características que extrajimos de las imágenes del pequeño dataset que construimos. Las otras dos columnas son el ID de cada fila(cada imagen, 0,1,2,3,4) y la clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea con el código guiado:\n",
    "\n",
    "En la carpeta \"Tarea codigo guiado\" se encuentra una subcarpeta llamada \"IMD049\", debe copiarse esta subcarpeta a la carpeta \"PH2 Dataset images\".\n",
    "\n",
    "Esto en esencia es añadir un nuevo dato al Dataset.\n",
    "\n",
    "A continuación debe utilizarse el código guiado para generar un dataframe de pandas con 6 ID (0, 1, 2, 3, 4, 5) conteniendo el último dato añadido.\n",
    "\n",
    "Finalmente, guardar el dataframe \"df\" como un archivo .csv y subirlo en la misma carpeta que la tarea solucionada.\n",
    "\n",
    "## Este ejercicio es de carácter obligatorio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
